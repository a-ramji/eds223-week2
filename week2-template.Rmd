## introduction
In this lab, we'll explore the basics of manipulating vector data in R using the **sf** package.
The following materials are modified from [Chapter 3 of Geocomputation with R by Rovin Lovelace](https://geocompr.robinlovelace.net/attr.html)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## prerequisites

```{r install, include=TRUE}
rm(list = ls())
library(sf)
library(spData)
library(tmap)
library(tidyverse)
```

## handling sf objects

Let's start by looking at how we can construct a **sf** object  
-   first we create a geometry for London by supplying a point and CRS  
-   then we supply some non-geographic attributes

```{r include=TRUE}
# create a geometry for London
# everything in sf is actually st

lnd_point <- st_point(c(0.1, 51.5))

# simple feature geometry list column 

lnd_geom <- st_sfc(lnd_point, crs = 4326) # geometry
# could also write crs = "EPSG:4326"

# create data.frame

lnd_attrib <- data.frame(
  name = "London",
  temperature = 25
)

# create an sf object with our point, list, and dataframe
lnd_sf <- st_sf(lnd_attrib, geometry = lnd_geom)
lnd_sf

# class sf and a data.frame
# each row is a different feature, R is handling each part differently
class(lnd_sf)
```

We can also check out what the CRS looks like.
```{r include=TRUE}

st_crs(lnd_sf)
# wkt = well known text

# doesn't have a projection associated with it
st_crs(lnd_sf)$IsGeographic


# checking the proj4string (alternate version of EPSG:4326, for example)
st_crs(lnd_sf)$proj4string


```


Now let's look at an existing **sf** object representing countries of the world

```{r include=TRUE}
# built-in into spData
# check class
class(world)
# check dimensions
dim(world)

# enter world in console to see more info 


```

We can see that this object contains both spatial data ("geom" column) and attributes about those geometries. We can perform operations on the attribute data, just like we would with a normal data frame.

```{r include=TRUE}
summary(world$lifeExp)

```

The geometry column is "sticky", meaning it will stick around unless we explicitly get rid of it. To convert this object into a data frame, we need to drop the geometry column.

```{r include=TRUE}
world |> 
  select(-geom)
# doesn't work! (still multipolygon column)

# you need to use a special function to get rid of them
world_df <- st_drop_geometry(world)
```

## vector attribute subsetting
The especially great things about **sf** objects is that we can use **tidyverse** functions on them!

We can select columns...
```{r include=TRUE}
world |> 
  select(name_long, pop)

```

Or remove columns...
```{r include=TRUE}
world |> 
  select(-subregion)

# still 177 features (geometries) but now only 10 columns
```

Or select AND rename columns
```{r include=TRUE}

world |> 
  select(name = name_long, population = pop)

```

Or filter observations based on variables
```{r include=TRUE}
world |> 
  filter(area_km2 < 10000)


world |> 
  filter(lifeExp >= 80)

```

## chaining commands with pipes
Because we can use **dplyr** functions with **sf** objects, we can chain together commands using the pipe operator.

Let's try to find the country in Asia with the highest life expectancy

## new function: slice_max()
```{r include=TRUE}

world |> 
  filter(continent == "Asia") |> 
  select(name_long, continent, lifeExp) |> 
  slice_max(lifeExp) # new function! super cool 

```
## new function: slice_min()
```{r}
world |> 
  select(name_long, continent, lifeExp) |> 
  slice_min(lifeExp) # new function! super cool 
```

## vector attribute aggregation
Aggregation is the process of summarizing data with one or more 'grouping' variables. For example, using the 'world' which provides information on countries of the world, we might want to aggregate to the level of continents. It is important to note that aggregating data *attributes* is a different process from aggregating *geographic* data, which we will cover later.

Let's try to find the total population within each continent.
```{r include=TRUE}
world |> 
  group_by(continent) |> 
  summarise(population = sum(pop, na.rm = TRUE)) |> 
  ungroup()

```

Let's also find the total area and number of countries in each continent
```{r include=TRUE}

world |> 
  group_by(continent) |> 
  summarise(population = sum(pop, na.rm = TRUE),
            total_area = sum(area_km2), 
            num_countries = n()) #|> # we don't need to put anything in n() because the number of rows are the number of countries !!
           # sort(pop)

```

Building on this, let's find the population density of each continent, find the continent's with highest density and arrange by the number of countries. WE'll drop the geometry column to speed things up.
## new function: arrange(desc())
```{r include=TRUE}

world |> 
  st_drop_geometry() |> 
  group_by(continent) |> 
  summarise(population = sum(pop, na.rm = TRUE),
            area_km2 = sum(area_km2, na.rm = TRUE),
            n_countries = n()) |> # sum number of countries in each continent
  mutate(density = round(population/area_km2)) |>  # getting a whole number
  slice_max(density, n = 3) |>  # see top 3
  arrange(desc(n_countries))  # new function!! 

```


## vector attribute joining
A critical part of many data science workflows is combining data sets based on common attributes. In R, we do this using multiple join functions, which follow SQL conventions.  

Let's start by looking a data set on national coffee production
```{r include=TRUE}
# pre-loaded dataset in spData

head(coffee_data) # conveniently, countries are also called name_long
class(coffee_data) # not an sf object
# coffee_data in console

```
## renaming within join function
```{r}
# example w renaming to join

test <- world |> 
  select(name = name_long)

# important!!! 
test_coffee <- left_join(test, coffee_data,
                         by = c("name" = "name_long")) # :) 

cleaned_coffee <- test_coffee |> 
  drop_na() |> 
  arrange(desc(coffee_production_2017))
```

We can combine this with the world data set, but joining based on country's names
```{r include=TRUE}
# whatever you put as the first dataset, that's what it's going to join on to 
world_coffee <- left_join(world, coffee_data, by = "name_long")

```

And plot what this looks like...
```{r include=TRUE}
tm_shape(world_coffee) +
  tm_polygons(col = "coffee_production_2016")


```

If we just wanted to keep countries that do have coffee data, we could use an inner join (or use drop_na)
```{r include=TRUE}
world_coffee_inner <- inner_join(world, coffee_data, by = "name_long")

nrow(world_coffee_inner)

nrow(coffee_data)
```

It looks like we lost some countries with coffee data, so let's figure out what's going on. We can find rows that didn't match using the **setdiff** function.
## super important point about building checks into workflow !!
```{r include=TRUE}

if(nrow(world_coffee_inner) != nrow(coffee_data)) {
  print("error in joining data!")
}

setdiff(coffee_data$name_long, world$name_long)

```

We see that one of the issues is that the two data sets use different naming conventions for the Democratic Republic of the Congo. We can use a string matching function to figure out what the DRC is called in the world data set.

## New function: str_subset
```{r include=TRUE}
stringr::str_subset(world$name_long, "Dem*.+Congo")
```

Now we can update the coffee data set with the matching name for the DRC.
## new function: grepl pattern matching and replacement
```{r include=TRUE}
# brackets notation: before comma = row, after = column
# find the row that matches this condition
drc = stringr::str_subset(world$name_long, "Dem*.+Congo")


coffee_data$name_long[ grepl("Congo, ", coffee_data$name_long) ] = drc # and keep all columns

coffee_data
```

And we can try the inner join again and hopefully the DRC now matches.
```{r include=TRUE}

world_coffee_inner <- inner_join(world, coffee_data, 
                                 by = "name_long")

nrow(world_coffee_inner)

if(nrow(world_coffee_inner) != nrow(coffee_data)) {
  print("error in joining data!")
}

setdiff(coffee_data$name_long, world$name_long)

# "Others" row isn't really relevant :) 
```
```{r}
class(world_coffee_inner)
```


Let's visualize what a the inner join did to our spatial object
```{r include=TRUE}
tm_shape(world_coffee_inner) +
  tm_polygons(col = "coffee_production_2017")
```

And let's test what would happen if we flipped the order of the data sets in the join
```{r include=TRUE}
# no longer sf 

flipped_coffee_inner <- inner_join(coffee_data, world, 
                                 by = "name_long")

class(flipped_coffee_inner)
```

